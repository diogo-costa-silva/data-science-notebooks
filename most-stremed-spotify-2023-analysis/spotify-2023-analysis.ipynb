{"cells":[{"cell_type":"markdown","metadata":{"id":"8O9gNgkxKDXQ"},"source":["# Analysis of the Most Streamed Spotify Songs in 2023\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Bt19Rn76K2Zq"},"source":["## 1. Business Understanding\n","\n","This initial phase focuses on understanding the project objectives and requirements from a business perspective, then converting this knowledge into a data mining problem definition and a preliminary plan."]},{"cell_type":"markdown","metadata":{"id":"JusGHdx2J_gL"},"source":["## 2. Data Understanding\n","\n","This phase involves initial data collection and familiarization, including data cleaning, transformation, and exploration to identify quality issues and insights about the data."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3110,"status":"ok","timestamp":1697994758440,"user":{"displayName":"Diogo Silva","userId":"17436513754207821399"},"user_tz":-60},"id":"px0Oc8_IPPcd"},"outputs":[],"source":["# Importing the necessary libraries\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import plotly.express as px\n","import plotly.graph_objects as go\n","\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n","from sklearn.linear_model import LinearRegression, LogisticRegression\n","from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n","from sklearn.cluster import KMeans\n","from statsmodels.formula.api import ols\n","\n","import folium as fl\n","import time\n","\n","# Setting styles for plots\n","plt.style.use('ggplot')\n","sns.set_theme(style=\"whitegrid\")\n","\n","# Ignore warnings in the output\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1697994758446,"user":{"displayName":"Diogo Silva","userId":"17436513754207821399"},"user_tz":-60},"id":"dmwmo2V_PRZc"},"outputs":[],"source":["# Load dataset\n","file_path = \"https://raw.githubusercontent.com/diogo-costa-silva/assets/main/data/spotify-2023.csv\"\n","df = pd.read_csv(file_path, encoding='ISO-8859-1')\n","\n","# Creating a copy of the dataframe for cleaning\n","df_cleaned = df.copy()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":600},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1697994758446,"user":{"displayName":"Diogo Silva","userId":"17436513754207821399"},"user_tz":-60},"id":"XFJZ8C1jPUyF","outputId":"7fcf5f91-c17c-4684-c350-7d57d80cac90"},"outputs":[{"data":{"text/html":["<div><div id=7f8747f2-8fdb-4107-b550-6954b774e5ef style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('7f8747f2-8fdb-4107-b550-6954b774e5ef').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>track_name</th>\n","      <th>artist(s)_name</th>\n","      <th>artist_count</th>\n","      <th>released_year</th>\n","      <th>released_month</th>\n","      <th>released_day</th>\n","      <th>in_spotify_playlists</th>\n","      <th>in_spotify_charts</th>\n","      <th>streams</th>\n","      <th>in_apple_playlists</th>\n","      <th>...</th>\n","      <th>bpm</th>\n","      <th>key</th>\n","      <th>mode</th>\n","      <th>danceability_%</th>\n","      <th>valence_%</th>\n","      <th>energy_%</th>\n","      <th>acousticness_%</th>\n","      <th>instrumentalness_%</th>\n","      <th>liveness_%</th>\n","      <th>speechiness_%</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Seven (feat. Latto) (Explicit Ver.)</td>\n","      <td>Latto, Jung Kook</td>\n","      <td>2</td>\n","      <td>2023</td>\n","      <td>7</td>\n","      <td>14</td>\n","      <td>553</td>\n","      <td>147</td>\n","      <td>141381703</td>\n","      <td>43</td>\n","      <td>...</td>\n","      <td>125</td>\n","      <td>B</td>\n","      <td>Major</td>\n","      <td>80</td>\n","      <td>89</td>\n","      <td>83</td>\n","      <td>31</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>LALA</td>\n","      <td>Myke Towers</td>\n","      <td>1</td>\n","      <td>2023</td>\n","      <td>3</td>\n","      <td>23</td>\n","      <td>1474</td>\n","      <td>48</td>\n","      <td>133716286</td>\n","      <td>48</td>\n","      <td>...</td>\n","      <td>92</td>\n","      <td>C#</td>\n","      <td>Major</td>\n","      <td>71</td>\n","      <td>61</td>\n","      <td>74</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>vampire</td>\n","      <td>Olivia Rodrigo</td>\n","      <td>1</td>\n","      <td>2023</td>\n","      <td>6</td>\n","      <td>30</td>\n","      <td>1397</td>\n","      <td>113</td>\n","      <td>140003974</td>\n","      <td>94</td>\n","      <td>...</td>\n","      <td>138</td>\n","      <td>F</td>\n","      <td>Major</td>\n","      <td>51</td>\n","      <td>32</td>\n","      <td>53</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>31</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Cruel Summer</td>\n","      <td>Taylor Swift</td>\n","      <td>1</td>\n","      <td>2019</td>\n","      <td>8</td>\n","      <td>23</td>\n","      <td>7858</td>\n","      <td>100</td>\n","      <td>800840817</td>\n","      <td>116</td>\n","      <td>...</td>\n","      <td>170</td>\n","      <td>A</td>\n","      <td>Major</td>\n","      <td>55</td>\n","      <td>58</td>\n","      <td>72</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>WHERE SHE GOES</td>\n","      <td>Bad Bunny</td>\n","      <td>1</td>\n","      <td>2023</td>\n","      <td>5</td>\n","      <td>18</td>\n","      <td>3133</td>\n","      <td>50</td>\n","      <td>303236322</td>\n","      <td>84</td>\n","      <td>...</td>\n","      <td>144</td>\n","      <td>A</td>\n","      <td>Minor</td>\n","      <td>65</td>\n","      <td>23</td>\n","      <td>80</td>\n","      <td>14</td>\n","      <td>63</td>\n","      <td>11</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>948</th>\n","      <td>My Mind &amp; Me</td>\n","      <td>Selena Gomez</td>\n","      <td>1</td>\n","      <td>2022</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>953</td>\n","      <td>0</td>\n","      <td>91473363</td>\n","      <td>61</td>\n","      <td>...</td>\n","      <td>144</td>\n","      <td>A</td>\n","      <td>Major</td>\n","      <td>60</td>\n","      <td>24</td>\n","      <td>39</td>\n","      <td>57</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>949</th>\n","      <td>Bigger Than The Whole Sky</td>\n","      <td>Taylor Swift</td>\n","      <td>1</td>\n","      <td>2022</td>\n","      <td>10</td>\n","      <td>21</td>\n","      <td>1180</td>\n","      <td>0</td>\n","      <td>121871870</td>\n","      <td>4</td>\n","      <td>...</td>\n","      <td>166</td>\n","      <td>F#</td>\n","      <td>Major</td>\n","      <td>42</td>\n","      <td>7</td>\n","      <td>24</td>\n","      <td>83</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>950</th>\n","      <td>A Veces (feat. Feid)</td>\n","      <td>Feid, Paulo Londra</td>\n","      <td>2</td>\n","      <td>2022</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>573</td>\n","      <td>0</td>\n","      <td>73513683</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>92</td>\n","      <td>C#</td>\n","      <td>Major</td>\n","      <td>80</td>\n","      <td>81</td>\n","      <td>67</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>951</th>\n","      <td>En La De Ella</td>\n","      <td>Feid, Sech, Jhayco</td>\n","      <td>3</td>\n","      <td>2022</td>\n","      <td>10</td>\n","      <td>20</td>\n","      <td>1320</td>\n","      <td>0</td>\n","      <td>133895612</td>\n","      <td>29</td>\n","      <td>...</td>\n","      <td>97</td>\n","      <td>C#</td>\n","      <td>Major</td>\n","      <td>82</td>\n","      <td>67</td>\n","      <td>77</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>952</th>\n","      <td>Alone</td>\n","      <td>Burna Boy</td>\n","      <td>1</td>\n","      <td>2022</td>\n","      <td>11</td>\n","      <td>4</td>\n","      <td>782</td>\n","      <td>2</td>\n","      <td>96007391</td>\n","      <td>27</td>\n","      <td>...</td>\n","      <td>90</td>\n","      <td>E</td>\n","      <td>Minor</td>\n","      <td>61</td>\n","      <td>32</td>\n","      <td>67</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table></div>"],"text/plain":["                              track_name      artist(s)_name  artist_count  \\\n","0    Seven (feat. Latto) (Explicit Ver.)    Latto, Jung Kook             2   \n","1                                   LALA         Myke Towers             1   \n","2                                vampire      Olivia Rodrigo             1   \n","3                           Cruel Summer        Taylor Swift             1   \n","4                         WHERE SHE GOES           Bad Bunny             1   \n","..                                   ...                 ...           ...   \n","948                         My Mind & Me        Selena Gomez             1   \n","949            Bigger Than The Whole Sky        Taylor Swift             1   \n","950                 A Veces (feat. Feid)  Feid, Paulo Londra             2   \n","951                        En La De Ella  Feid, Sech, Jhayco             3   \n","952                                Alone           Burna Boy             1   \n","\n","     released_year  released_month  released_day  in_spotify_playlists  \\\n","0             2023               7            14                   553   \n","1             2023               3            23                  1474   \n","2             2023               6            30                  1397   \n","3             2019               8            23                  7858   \n","4             2023               5            18                  3133   \n","..             ...             ...           ...                   ...   \n","948           2022              11             3                   953   \n","949           2022              10            21                  1180   \n","950           2022              11             3                   573   \n","951           2022              10            20                  1320   \n","952           2022              11             4                   782   \n","\n","     in_spotify_charts    streams  in_apple_playlists  ...  bpm key   mode  \\\n","0                  147  141381703                  43  ...  125   B  Major   \n","1                   48  133716286                  48  ...   92  C#  Major   \n","2                  113  140003974                  94  ...  138   F  Major   \n","3                  100  800840817                 116  ...  170   A  Major   \n","4                   50  303236322                  84  ...  144   A  Minor   \n","..                 ...        ...                 ...  ...  ...  ..    ...   \n","948                  0   91473363                  61  ...  144   A  Major   \n","949                  0  121871870                   4  ...  166  F#  Major   \n","950                  0   73513683                   2  ...   92  C#  Major   \n","951                  0  133895612                  29  ...   97  C#  Major   \n","952                  2   96007391                  27  ...   90   E  Minor   \n","\n","    danceability_%  valence_% energy_% acousticness_%  instrumentalness_%  \\\n","0               80         89       83             31                   0   \n","1               71         61       74              7                   0   \n","2               51         32       53             17                   0   \n","3               55         58       72             11                   0   \n","4               65         23       80             14                  63   \n","..             ...        ...      ...            ...                 ...   \n","948             60         24       39             57                   0   \n","949             42          7       24             83                   1   \n","950             80         81       67              4                   0   \n","951             82         67       77              8                   0   \n","952             61         32       67             15                   0   \n","\n","     liveness_%  speechiness_%  \n","0             8              4  \n","1            10              4  \n","2            31              6  \n","3            11             15  \n","4            11              6  \n","..          ...            ...  \n","948           8              3  \n","949          12              6  \n","950           8              6  \n","951          12              5  \n","952          11              5  \n","\n","[953 rows x 24 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{"id":"0jVkCAhdPpLY"},"source":["The dataframe contains various features related to songs, artists, and their attributes or performance metrics across different platforms.\n","\n","In order to better understand each feature present in the dataset, here's a quick overview of the dataset columns based on the initial few rows:\n","\n","- track_name: The title of the tracks.\n","- artist(s)_name: Names of the artist(s) associated with each track.\n","- artist_count: The number of artists contributing to each track.\n","- released_year, released_month, released_day: The release date components for each track.\n","- Various metrics representing the track's presence and popularity on different music streaming platforms: in_spotify_playlists, in_spotify_charts, streams, in_apple_playlists, in_apple_charts, in_deezer_playlists, in_deezer_charts, in_shazam_charts\n","- bpm: The tempo of the track, measured in beats per minute.\n","- key: The key in which the track is composed.\n","- mode: The mode of the track (major or minor).\n","- Various metrics representing the track's musical qualities, including danceability_%, valence_%, energy_%, acousticness_%, instrumentalness_%, liveness_%, speechiness_%.\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1697994759943,"user":{"displayName":"Diogo Silva","userId":"17436513754207821399"},"user_tz":-60},"id":"xB90wdravFAs","outputId":"6c26292b-bc64-4d82-d45a-939d58b99427"},"outputs":[{"data":{"text/plain":["(953, 24)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":259,"status":"ok","timestamp":1697994761340,"user":{"displayName":"Diogo Silva","userId":"17436513754207821399"},"user_tz":-60},"id":"LPACu-jN4j6r","outputId":"d6e69685-520e-48b5-9915-c70e91322600"},"outputs":[{"data":{"text/plain":["Index(['track_name', 'artist(s)_name', 'artist_count', 'released_year',\n","       'released_month', 'released_day', 'in_spotify_playlists',\n","       'in_spotify_charts', 'streams', 'in_apple_playlists', 'in_apple_charts',\n","       'in_deezer_playlists', 'in_deezer_charts', 'in_shazam_charts', 'bpm',\n","       'key', 'mode', 'danceability_%', 'valence_%', 'energy_%',\n","       'acousticness_%', 'instrumentalness_%', 'liveness_%', 'speechiness_%'],\n","      dtype='object')"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.columns"]},{"cell_type":"markdown","metadata":{},"source":["### Check Data Quality"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1697994762669,"user":{"displayName":"Diogo Silva","userId":"17436513754207821399"},"user_tz":-60},"id":"KZNSiCba4ksK","outputId":"795ff083-0d17-40cf-e011-23d21fdc5df0"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 953 entries, 0 to 952\n","Data columns (total 24 columns):\n"," #   Column                Non-Null Count  Dtype \n","---  ------                --------------  ----- \n"," 0   track_name            953 non-null    object\n"," 1   artist(s)_name        953 non-null    object\n"," 2   artist_count          953 non-null    int64 \n"," 3   released_year         953 non-null    int64 \n"," 4   released_month        953 non-null    int64 \n"," 5   released_day          953 non-null    int64 \n"," 6   in_spotify_playlists  953 non-null    int64 \n"," 7   in_spotify_charts     953 non-null    int64 \n"," 8   streams               953 non-null    object\n"," 9   in_apple_playlists    953 non-null    int64 \n"," 10  in_apple_charts       953 non-null    int64 \n"," 11  in_deezer_playlists   953 non-null    object\n"," 12  in_deezer_charts      953 non-null    int64 \n"," 13  in_shazam_charts      903 non-null    object\n"," 14  bpm                   953 non-null    int64 \n"," 15  key                   858 non-null    object\n"," 16  mode                  953 non-null    object\n"," 17  danceability_%        953 non-null    int64 \n"," 18  valence_%             953 non-null    int64 \n"," 19  energy_%              953 non-null    int64 \n"," 20  acousticness_%        953 non-null    int64 \n"," 21  instrumentalness_%    953 non-null    int64 \n"," 22  liveness_%            953 non-null    int64 \n"," 23  speechiness_%         953 non-null    int64 \n","dtypes: int64(17), object(7)\n","memory usage: 178.8+ KB\n"]}],"source":["df.info()"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["track_name               0\n","artist(s)_name           0\n","artist_count             0\n","released_year            0\n","released_month           0\n","released_day             0\n","in_spotify_playlists     0\n","in_spotify_charts        0\n","streams                  0\n","in_apple_playlists       0\n","in_apple_charts          0\n","in_deezer_playlists      0\n","in_deezer_charts         0\n","in_shazam_charts        50\n","bpm                      0\n","key                     95\n","mode                     0\n","danceability_%           0\n","valence_%                0\n","energy_%                 0\n","acousticness_%           0\n","instrumentalness_%       0\n","liveness_%               0\n","speechiness_%            0\n","dtype: int64"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# Checking for missing values\n","missing_values = df.isnull().sum()\n","missing_values"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# Checking for duplicates\n","num_duplicates = df.duplicated().sum()\n","num_duplicates"]},{"cell_type":"markdown","metadata":{"id":"ZnbH6lJw4oGz"},"source":["### Explore unique feature values"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"pMji7ENhJgp6"},"outputs":[],"source":["#df['released_year'].unique()"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"8t4F0yWiJjiU"},"outputs":[],"source":["#df['released_month'].unique()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"QkvoF4soJoBy"},"outputs":[],"source":["#df['released_day'].unique()"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"mNNaeYTU3YNw"},"outputs":[],"source":["#df['streams'].unique()"]},{"cell_type":"markdown","metadata":{"id":"5YZFt4evZz7Q"},"source":[" it seems there's a peculiar value: 'BPM110KeyAModeMajorDanceability53Valence75Energy69Acousticness7Instrumentalness0Liveness17Speechiness3'. This doesn't follow the numerical pattern that we would expect for a column that's supposed to represent streaming counts."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"7qFtgVnH3KL8"},"outputs":[],"source":["#df['in_deezer_playlists'].unique()"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"GJqKHONT3lJv"},"outputs":[],"source":["#df['in_shazam_charts'].unique()"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"SAufax5i3rxz"},"outputs":[],"source":["#df['bpm'].unique()"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"XnUPk4sQ4Jni"},"outputs":[],"source":["#df['mode'].unique()"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"0oiozDcz4P32"},"outputs":[],"source":["#df['danceability_%'].unique()"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"TE7ozELv4Ydq"},"outputs":[],"source":["#df['liveness_%'].unique()"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"8B29pbz_4ckg"},"outputs":[],"source":["#df['instrumentalness_%'].unique()"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"Jt35yKN040C7"},"outputs":[],"source":["#df['speechiness_%'].unique()"]},{"cell_type":"markdown","metadata":{"id":"1zqGhdM7IHCY"},"source":["### 2.1. Data Pre-processing\n","\n","Before we dive into individual data cleaning tasks, let's summarize the initial steps we need to undertake for <b>Data Cleaning and Transformation</b>:\n","<br>\n","1. Transforming Date Features:\n","<br>\n","The 'released_year', 'released_month', and 'released_day' fields are currently separate and in integer format. We need to combine these into a single datetime object to allow more efficient temporal analysis.\n","<br>\n","2. Cleaning Specific Fields:\n","<br>\n","The 'streams' field appears to have an inconsistent entry which we'll need to investigate and clean.\n","The 'in_deezer_playlists' and 'in_shazam_charts' fields contain numbers with commas, which should be standard integers. We'll convert these.\n","<br>\n","3. Reviewing Categorical Variables:\n","<br>\n","The 'key' and 'mode' fields are non-numeric and could be considered categorical. We'll review these to decide on the most appropriate treatment, potentially converting them into a category type for efficient processing.\n","<br>\n","4. Extended Data Exploration:\n","<br>\n","Once the data is cleaned, we will perform an extensive exploratory data analysis (EDA) to uncover insights, patterns, and potential issues in the data. This EDA will involve statistical summaries, visualizations, and various other techniques to understand the data deeply.\n","\n","\n","\n","1. Convert 'released_year', 'released_month', and 'released_day' into a single datetime object.\n","2. Clean the 'streams' column and convert its data type.\n","3. Remove commas from 'in_deezer_playlists' and 'in_shazam_charts' and convert them to integers.\n","4. Discuss the potential conversion of 'key' and 'mode' into category types.\n","5. Handle NaN values in ‘in_shazam_charts’ and ‘key’."]},{"cell_type":"markdown","metadata":{"id":"6pKnIW-xMdWW"},"source":["We'll start by addressing the first item on our data cleaning list: converting the 'released_year', 'released_month', and 'released_day' columns into a single datetime column. This transformation is important because it allows for more efficient handling of the data, particularly for operations that involve date calculations, filtering, and aggregation."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":389,"status":"ok","timestamp":1697994775476,"user":{"displayName":"Diogo Silva","userId":"17436513754207821399"},"user_tz":-60},"id":"62gb1ZJ2Xw4o","outputId":"f9773a93-9330-439e-9a4f-63f70276c9fe"},"outputs":[{"data":{"text/html":["<div><div id=d8daf5e1-6bd0-4a28-9ab5-61cd75376ee4 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('d8daf5e1-6bd0-4a28-9ab5-61cd75376ee4').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>released_year</th>\n","      <th>released_month</th>\n","      <th>released_day</th>\n","      <th>release_date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2023</td>\n","      <td>7</td>\n","      <td>14</td>\n","      <td>2023-07-14</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2023</td>\n","      <td>3</td>\n","      <td>23</td>\n","      <td>2023-03-23</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2023</td>\n","      <td>6</td>\n","      <td>30</td>\n","      <td>2023-06-30</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2019</td>\n","      <td>8</td>\n","      <td>23</td>\n","      <td>2019-08-23</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2023</td>\n","      <td>5</td>\n","      <td>18</td>\n","      <td>2023-05-18</td>\n","    </tr>\n","  </tbody>\n","</table></div>"],"text/plain":["   released_year  released_month  released_day release_date\n","0           2023               7            14   2023-07-14\n","1           2023               3            23   2023-03-23\n","2           2023               6            30   2023-06-30\n","3           2019               8            23   2019-08-23\n","4           2023               5            18   2023-05-18"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# Step 1: Ensure the year, month, and day columns are integers (they should already be)\n","for col in ['released_year', 'released_month', 'released_day']:\n","    df_cleaned[col] = df_cleaned[col].astype(int)\n","\n","# Step 2: Combine the year, month, and day into a single column (as a string)\n","df_cleaned['release_date'] = df_cleaned['released_year'].astype(str) + '-' + \\\n","                             df_cleaned['released_month'].astype(str).str.zfill(2) + '-' + \\\n","                             df_cleaned['released_day'].astype(str).str.zfill(2)  # zfill ensures a format like 2023-07-14\n","\n","# Step 3: Convert the 'release_date' column to a datetime object\n","df_cleaned['release_date'] = pd.to_datetime(df_cleaned['release_date'], format='%Y-%m-%d')\n","\n","# Step 4: (Optional) Drop the original 'released_year', 'released_month', and 'released_day' columns\n","# We will retain these columns for now, as they might be useful for analysis later on.\n","\n","# Display the first few rows of the cleaned dataframe to verify our changes\n","df_cleaned[['released_year', 'released_month', 'released_day', 'release_date']].head()\n"]},{"cell_type":"markdown","metadata":{"id":"_j0UFhZZRuDs"},"source":["The 'released_year', 'released_month', and 'released_day' columns have been successfully combined into a new 'release_date' column, with the date represented as a datetime object. This format is more suitable for any subsequent operations that involve date calculations or aggregations.\n","\n","Here's a brief overview of what we did:\n","\n","We confirmed that the 'released_year', 'released_month', and 'released_day' columns were indeed integers.\n","We concatenated these columns into a single 'release_date' column, ensuring proper zero-padding for single-digit months and days to maintain the 'YYYY-MM-DD' format.\n","We converted the 'release_date' column from a string to a datetime object using pandas' to_datetime method, providing the specific format to ensure accurate parsing.\n","We opted to retain the original year, month, and day columns, considering they might be useful for certain types of analysis where these individual components are needed.\n","With this transformation, operations that require date functionality will be much more straightforward, such as sorting by date, calculating time spans, and aggregating based on specific time periods (e.g., monthly or yearly).\n","\n","Next, we will handle the 'streams' column, which appears to have an inconsistent entry. We'll need to clean this data and convert the column to the appropriate data type.\n","\n","Here are the steps we'll take to clean this column:\n","\n","1. Investigate the unusual entry in the 'streams' column and determine whether it's an isolated case or part of a broader issue.\n","2. If it's an isolated incident, we may directly correct this entry. If it's a systematic issue, we'll need a more general approach.\n","3. Convert the 'streams' column to the appropriate numerical type (integer) after handling the anomalous entries.\n","4. Consider handling any other potential outliers or anomalies that could affect the analysis.\n","\n","Let's begin by examining the problematic value and understanding the extent of this issue within the column."]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":415,"status":"ok","timestamp":1697995317176,"user":{"displayName":"Diogo Silva","userId":"17436513754207821399"},"user_tz":-60},"id":"PCAE2E1cYNUV","outputId":"a57c4858-785f-4a77-ad2d-21d84101da03"},"outputs":[{"data":{"text/html":["<div><div id=70276db7-7b45-4d5c-9646-848d9a11607f style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('70276db7-7b45-4d5c-9646-848d9a11607f').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>track_name</th>\n","      <th>streams</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>574</th>\n","      <td>Love Grows (Where My Rosemary Goes)</td>\n","      <td>BPM110KeyAModeMajorDanceability53Valence75Energy69Acousticness7Instrumentalness0Liveness17Speechiness3</td>\n","    </tr>\n","  </tbody>\n","</table></div>"],"text/plain":["                              track_name  \\\n","574  Love Grows (Where My Rosemary Goes)   \n","\n","                                               streams  \n","574  BPM110KeyAModeMajorDanceability53Valence75Ener...  "]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Step 1: Investigate the unusual entry in the 'streams' column.\n","problematic_entries = df_cleaned[df_cleaned['streams'].astype(str).str.contains(r'[a-zA-Z]')]\n","\n","# Return the problematic entries for examination\n","problematic_entries[['track_name', 'streams']]\n"]},{"cell_type":"markdown","metadata":{"id":"KbvlQh3CaPTu"},"source":["The investigation reveals that there is indeed an anomalous entry within the 'streams' column. Specifically, the track \"Love Grows (Where My Rosemary Goes)\" has a string of non-numeric characters, which appears to be a concatenation of various song attributes rather than the expected numerical value representing stream counts.\n","\n","Given that this is an isolated incident, we have a few approaches to rectify this:\n","\n","- Correction: If we know the correct number of streams or can retrieve it, we could directly replace the incorrect entry.\n","- Removal: We could remove this specific entry from our dataset to prevent it from skewing any analytical results.\n","- Imputation: In the absence of the correct data, we might impute a value based on similar tracks or the average number of streams, though this approach can introduce bias.\n","\n","For the sake of maintaining the integrity of the dataset size and structure, and in the absence of the actual value, we might lean towards imputation. However, the ideal approach would be to retrieve the correct data if accessible.\n","\n","In this scenario, without the actual streaming count, we'll opt to replace this entry with a 'NaN' so it won't interfere with numerical conversions and calculations. Later, we can decide if we want to impute an estimated value or handle the 'NaN' in another manner."]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":384,"status":"ok","timestamp":1697995386664,"user":{"displayName":"Diogo Silva","userId":"17436513754207821399"},"user_tz":-60},"id":"Ykw04cXvYNK9","outputId":"4574d346-f203-4f01-e8b3-f1bb764e2056"},"outputs":[{"data":{"text/plain":["count    9.520000e+02\n","mean     5.141374e+08\n","std      5.668569e+08\n","min      2.762000e+03\n","25%      1.416362e+08\n","50%      2.905309e+08\n","75%      6.738690e+08\n","max      3.703895e+09\n","Name: streams, dtype: float64"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# Replace the problematic value with NaN (represented as np.nan in the dataset)\n","df_cleaned.loc[df_cleaned['streams'].astype(str).str.contains(r'[a-zA-Z]'), 'streams'] = np.nan\n","\n","# Convert the 'streams' column to a float (since we introduced NaN, we can't convert to int directly)\n","df_cleaned['streams'] = df_cleaned['streams'].astype(float)\n","\n","# Check if the conversion was successful and how the 'streams' column looks now\n","df_cleaned['streams'].describe()  # This will give us statistical info including count (to check if we have one less entry)"]},{"cell_type":"markdown","metadata":{"id":"VO6U4eTFafsK"},"source":["The cleanup for the 'streams' column was successful. We replaced the anomalous entry with 'NaN' and converted the rest of the column to float type (since integers can't handle NaN values).\n","\n","This column is now clean for numerical operations and analyses, although we'll need to decide later how to handle the 'NaN' entry, whether by imputation, removal, or some other strategy.\n","\n","Next, we'll address the 'in_deezer_playlists' and 'in_shazam_charts' columns, which contain numbers with commas and should be converted to integers.\n","\n","Here's our plan of action:\n","\n","1. Replace the commas from the 'in_deezer_playlists' and 'in_shazam_charts' columns to eliminate the thousands separators.\n","2. Convert these cleaned columns to integers to enable numerical operations.\n","3. Verify the success of these operations by checking the data types or performing statistical summaries.\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1697995556745,"user":{"displayName":"Diogo Silva","userId":"17436513754207821399"},"user_tz":-60},"id":"LD0ZxrfqYM5_","outputId":"a13bcb1f-02d7-464d-d1d6-287aa594bc4c"},"outputs":[{"data":{"text/plain":["in_deezer_playlists    float64\n","in_shazam_charts       float64\n","dtype: object"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# Step 1: Remove commas from the specified columns\n","df_cleaned['in_deezer_playlists'] = df_cleaned['in_deezer_playlists'].str.replace(',', '').astype(float)\n","df_cleaned['in_shazam_charts'] = df_cleaned['in_shazam_charts'].str.replace(',', '').astype(float)\n","\n","# Convert these columns to integers (we use float first because NaN values cannot be converted to int)\n","# Here, we are not converting to int after replacing commas because of the presence of NaN values.\n","\n","# Step 3: Verify the operations by checking the data types of these columns and view statistical summaries.\n","data_types = df_cleaned[['in_deezer_playlists', 'in_shazam_charts']].dtypes\n","\n","# Display the data types of the cleaned columns\n","data_types"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":256,"status":"ok","timestamp":1697996092320,"user":{"displayName":"Diogo Silva","userId":"17436513754207821399"},"user_tz":-60},"id":"cxkTmyFEbVME","outputId":"3d7b1d61-5f9f-4c44-b535-4ca0cf5d08a7"},"outputs":[],"source":["#df_cleaned['in_shazam_charts'].unique()"]},{"cell_type":"markdown","metadata":{"id":"qVSLXcG5bIQ5"},"source":["The cleaning for the 'in_deezer_playlists' and 'in_shazam_charts' columns was successful. We removed the commas and converted the values to the float data type. We used float instead of integer due to the presence of 'NaN' values, which are not compatible with the integer type.\n","\n","These columns are now prepared for numerical analysis and mathematical operations, keeping in mind that we have 'NaN' values that we might need to address later, depending on the specific requirements of our subsequent analysis.\n","\n","Next, we should discuss the potential categorization of the 'key' and 'mode' columns and then handle the NaN values in the 'in_shazam_charts' and 'key' columns.\n","\n","The 'key' and 'mode' columns in your dataset represent categorical data, indicating the musical key and mode (major or minor) of each track. While these are represented as strings (object type) in your dataset, converting them to a category data type can be beneficial for several reasons:\n","\n","- Efficiency: Category data type often uses less memory and can speed up operations like sorting and comparison.\n","- Integrity: It restricts the data to a specific set of values, ensuring consistency.\n","- Usefulness for Analysis: Categorical data is handy for statistical methods that are designed to handle categories rather than numerical data, and it's essential for certain visualizations and groupings.\n","\n","Here's our plan for this part:\n","\n","1. Examine the unique values in 'key' and 'mode' to understand the range of categories we're dealing with.\n","2. Convert 'key' and 'mode' to the category data type.\n","3. Validate the conversion."]},{"cell_type":"code","execution_count":24,"metadata":{"id":"3OIWXTiTYMw_"},"outputs":[{"data":{"text/plain":["(array(['B', 'C#', 'F', 'A', 'D', 'F#', nan, 'G#', 'G', 'E', 'A#', 'D#'],\n","       dtype=object),\n"," array(['Major', 'Minor'], dtype=object),\n"," key     category\n"," mode    category\n"," dtype: object)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# Step 1: Examine the unique values in 'key' and 'mode'\n","unique_keys = df_cleaned['key'].unique()\n","unique_modes = df_cleaned['mode'].unique()\n","\n","# Step 2: Convert 'key' and 'mode' to the category data type\n","df_cleaned['key'] = df_cleaned['key'].astype('category')\n","df_cleaned['mode'] = df_cleaned['mode'].astype('category')\n","\n","# Step 3: Validate the conversion by checking the new data types\n","new_data_types = df_cleaned[['key', 'mode']].dtypes\n","\n","unique_keys, unique_modes, new_data_types\n"]},{"cell_type":"markdown","metadata":{},"source":["The conversion was successful. Let's review what we've accomplished:\n","\n","1. We examined the unique values in both the 'key' and 'mode' columns. The 'key' column contains various musical keys, and there are 'NaN' values present, indicating missing data. The 'mode' column specifies whether the track is in a major or minor mode.\n","\n","- Unique keys: 'B', 'C#', 'F', 'A', 'D', 'F#', 'G#', 'G', 'E', 'A#', 'D#', and NaN (missing values)\n","- Unique modes: 'Major', 'Minor'\n","\n","2. We successfully converted both columns to the category data type, as reflected in the data types' confirmation:\n","\n","- 'key': category\n","- 'mode': category\n","\n","\n","These categorical data types are more efficient for storage and are beneficial for analysis, particularly when dealing with non-numeric data that has a limited set of values. They also make the dataset more consistent and easier to manage, especially for operations that involve grouping, filtering, or creating visuals based on these specific categories.\n","\n","Next, we need to address the 'NaN' values in the 'in_shazam_charts' and 'key' columns. Handling missing data is crucial as it can significantly impact the results of your analysis.\n","\n","Handling missing data is a critical step in data cleaning because improper handling can lead to biased results. There are several strategies to deal with missing data, each with its pros and cons:\n","\n","- Deletion: This is the simplest strategy, involving the removal of rows with missing data. However, it can lead to a loss of information if the dataset isn't large.\n","- Imputation: This strategy involves filling in the missing values based on other information. Common methods include using the mean, median, mode, or using predictive models. This method can introduce bias if not done carefully.\n","- Flagging and Filling: This involves two steps: flagging missing values with an indicator and then filling the missing values with a non-null value (zero, mean, etc.). This helps maintain the size of the dataset.\n","- Leave as Missing: For some algorithms, you might leave them as missing (NaN), especially algorithms that can handle missing values inherently.\n","We need to consider the nature of our data and the context of our analysis before choosing a strategy. Given that 'key' is categorical and 'in_shazam_charts' is numerical, the approach may differ.\n","\n","Let's start by understanding the extent of missing data in these columns. We'll calculate the percentage of missing values for each column and then proceed based on the results."]},{"cell_type":"code","execution_count":32,"metadata":{"id":"wAzHT6IPYMtj"},"outputs":[{"data":{"text/plain":["in_shazam_charts    5.24659\n","key                 9.96852\n","dtype: float64"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["# Calculate the total number of missing values in each column\n","missing_values = df_cleaned[['in_shazam_charts', 'key']].isnull().sum()\n","\n","# Calculate the percentage of missing values\n","total_rows = df_cleaned.shape[0]\n","percentage_missing = (missing_values / total_rows) * 100\n","\n","percentage_missing"]},{"cell_type":"markdown","metadata":{},"source":["The calculation of missing data reveals the following:\n","\n","- 'in_shazam_charts': Approximately 5.25% of the entries are missing.\n","- 'key': Around 9.97% of the entries are missing.\n","Given these percentages, we need to choose a strategy that balances data integrity with analytical usefulness. Here are the proposed strategies for each column:\n","\n","1. 'in_shazam_charts' (Numerical): Since the missing percentage is relatively low, we could opt for imputation to retain as much data as possible. Using the median or mean of the existing values could be a suitable approach because these are robust against outliers. Alternatively, if there's a reason to believe that a '0' is a valid substitute (perhaps the song did not make it to the charts), we could use zero imputation.\n","\n","2. 'key' (Categorical): Deletion is often less desirable for categorical data, especially under 10% missing, as it could lead to biased analyses. A common strategy is to impute with the most frequent category (mode) or to create a separate category, such as 'Unknown' or 'Not Available', to acknowledge the absence of data. This method keeps the dataset's size and can provide additional insights during analysis.\n","\n","We'll proceed with these strategies. Let's start with the 'in_shazam_charts' column. We'll impute the missing values with the median (to avoid being affected by potential outliers)."]},{"cell_type":"code","execution_count":34,"metadata":{"id":"3cl5lbjBYMg2"},"outputs":[{"data":{"text/plain":["in_shazam_charts    0\n","key                 0\n","dtype: int64"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["# Step 1: Add 'Unknown' to the existing categories of the 'key' column\n","df_cleaned['key'] = df_cleaned['key'].cat.add_categories('Unknown')\n","\n","# Step 2: Impute missing values with 'Unknown'\n","df_cleaned['key'].fillna('Unknown', inplace=True)\n","\n","# Verify if the missing values are handled\n","new_missing_values = df_cleaned[['in_shazam_charts', 'key']].isnull().sum()\n","new_missing_values\n"]},{"cell_type":"markdown","metadata":{},"source":["The missing data handling was successful. We added 'Unknown' as a category to the 'key' column and then filled in the missing entries. Both the 'in_shazam_charts' and 'key' columns now have zero missing values, as evidenced by the counts.\n","\n","Here's a summary of what we did:\n","\n","1. 'in_shazam_charts': We calculated the median of the existing values and used this to impute the missing data. This approach ensures that we do not introduce significant bias into the distribution of this column.\n","\n","2. 'key': We added 'Unknown' as a new category and then filled in the missing data with this value. This strategy acknowledges the absence of data while maintaining the dataset's consistency and size.\n","\n","With these steps, we've preserved the integrity of our dataset and avoided potential biases associated with dropping rows or imputing them without acknowledgment of their missing nature.\n","\n","This takes care of the necessary data cleaning and preparation tasks for now. The dataset is now in a much better state for any further analysis you wish to perform.\n","\n","## Saving the Cleaned Dataset\n","Let's start by saving your cleaned data (df_cleaned) as a new CSV file. This practice is essential for several reasons:\n","\n","- Preservation of Clean Data: You ensure that all the cleaning and transformation steps applied do not have to be repeated. It saves time and prevents errors in re-execution.\n","- Version Control: It helps in maintaining the original version of the dataset intact for any backtracking, comparison, or audit purposes.\n","- Ease of Sharing: Clean datasets can be easily shared with others working on the project, ensuring everyone uses the same, consistent data.\n","I will now save df_cleaned as a new CSV file."]},{"cell_type":"code","execution_count":38,"metadata":{"id":"pQtAgsxTYMSu"},"outputs":[{"data":{"text/plain":["'/Users/diogosilva/Desktop/projeto_metyis/spotify_cleaned.csv'"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["# Define the path for the new cleaned data file\n","cleaned_file_path = '/Users/diogosilva/Desktop/projeto_metyis/spotify_cleaned.csv'\n","\n","# Save the cleaned DataFrame to a new CSV file\n","df_cleaned.to_csv(cleaned_file_path, index=False)  # The index=False parameter prevents writing row indices\n","\n","# Provide the path for confirmation\n","cleaned_file_path"]},{"cell_type":"markdown","metadata":{},"source":["### In-depth Data Exploration and Analysis\n","\n","Now that we have a clean dataset, we can dive into a comprehensive data exploration and analysis phase. This stage is crucial because it allows us to extract meaningful insights, identify patterns and trends, and perhaps discover hidden correlations between different variables. Here's a detailed plan:\n","\n","1. Descriptive Statistics:\n","- Purpose: Understand basic characteristics of the data.\n","- Methods: Calculate mean, median, mode, range, quartiles, and standard deviation for numerical data. For categorical data, analyze the frequency distribution.\n","- Outcome: Establish a foundational understanding of the data's central tendencies and dispersion.\n","  \n","2. Visual Data Exploration:\n","- Purpose: Identify patterns, spot anomalies, and form hypotheses.\n","- Methods: Use histograms, box plots, and scatter plots for numerical data. For categorical data, use bar charts and pie charts. Heatmaps can show correlations.\n","- Outcome: Visual insights into distributions, correlations, and potential outliers or anomalies.\n","\n","3. Temporal Analysis:\n","- Purpose: Explore trends over time.\n","- Methods: Time-series analysis on variables like 'streams' or 'in_spotify_playlists' to identify trends, seasonal patterns, or irregularities.\n","- Outcome: Insights into how song attributes or popularity metrics have evolved.\n","\n","4. Feature Relationships and Correlations:\n","- Purpose: Understand how different variables influence each other.\n","- Methods: Correlation matrices, scatter plots, and possibly more advanced statistical methods (like chi-square tests for categorical data).\n","- Outcome: Identification of significant positive or negative relationships between features.\n","\n","5. Advanced Segment Analysis:\n","- Purpose: Deep dive into subsets of data.\n","- Methods: Grouping or segmenting the data by certain criteria (e.g., by 'artist', 'key', or 'mode') and performing a comparative analysis.\n","- Outcome: Comparative insights, such as how different artists' songs perform or how song characteristics differ between major and minor modes.\n","\n","6. Anomaly Detection:\n","- Purpose: Identify unusual data points that deviate from the norm.\n","- Methods: Statistical methods (like Z-score, IQR) or visual methods (like studying the scatter plots or box plots).\n","- Outcome: Detection of outliers that could be errors or valuable insights.\n","\n","7. Hypothesis Testing:\n","- Purpose: Confirm or reject assumptions.\n","- Methods: T-tests, ANOVA, or non-parametric tests to confirm the statistical significance of observations.\n","- Outcome: Validated or refuted hypotheses, providing depth to our insights.\n","\n","8. Predictive Analytics (Optional):\n","- Purpose: Predict outcomes based on the data.\n","- Methods: Regression analysis, or machine learning algorithms like random forest or neural networks, if the project scope allows.\n","- Outcome: Models that can predict, for example, a song's popularity based on its attributes.\n","\n","9. Report and Communicate Findings:\n","- Purpose: Share insights and recommendations.\n","- Methods: Compile the analyses into a comprehensive report or presentation, using clear visualizations and concise interpretations.\n","- Outcome: A ready-to-share report that conveys the story behind the data, supporting decision-making."]},{"cell_type":"markdown","metadata":{},"source":["## Exploratory Data Analysis (EDA) \n","\n","This stage is crucial as it involves understanding the distribution and characteristics of the data, which informs the subsequent steps of feature engineering and model selection.\n","\n","We'll begin with univariate analysis, which involves analyzing one variable at a time, and then move to multivariate analysis, where we examine relationships between multiple variables. Throughout this process, we'll create visualizations and use statistical measures to understand the data better.\n","\n","### Univariate analysis\n","\n","This process involves examining one variable at a time and is foundational in understanding the data's overall characteristics. We'll use both graphical and statistical methods for a comprehensive analysis.\n","\n","Here's how we'll proceed:\n","\n","1. Selection of Variables: We'll select a few key variables to start. Given the nature of your data, it would be insightful to begin with variables that represent the characteristics of the songs, such as 'danceability_%', 'energy_%', and 'valence_%'. These features often have interesting distributions and can tell us a lot about the dataset's nature.\n","\n","2. Statistical Summary: For each variable, we'll calculate descriptive statistics, including measures of central tendency (mean, median) and measures of dispersion (range, variance, standard deviation, skewness, kurtosis). This gives us a clear, concise view of the data's central values and variability.\n","\n","3. Visualization: We'll create visual representations of each variable using histograms or box plots. Histograms will allow us to see the data distribution and identify any skewness. In contrast, box plots provide insights into the data's quartiles and potential outliers.\n","\n","4. Interpretation: For each analysis, we'll provide an interpretation of the statistics and visualizations, explaining what they tell us about the data. This step is crucial for understanding any implications or interesting characteristics of the variables.\n","\n","By conducting a thorough univariate analysis, we lay a solid foundation for the more complex bivariate and multivariate analyses to follow, ensuring we fully understand the variables before we start exploring their interactions.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hQSENZhKYMQB"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h1pKvG1mYMNe"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iFDQ31RBYMK4"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_2hbfHykYMHt"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FFcPXVg7YMEa"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IoA2HEnRYL7j"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jpdmNUSMSf9F"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hqiq4vjBSf6z"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MzAUB5nTSf4q"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_6j_LY5pSfwi"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"SmGLFTEPFr9n"},"source":["### Basic descriptive statistics and general data checks\n","\n","We'll check for any missing or duplicate values and understand the data types and summary statistics of each column. This step is crucial for deciding how to handle preprocessing in the Data Preparation phase."]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"executionInfo":{"elapsed":379,"status":"ok","timestamp":1697990031962,"user":{"displayName":"Diogo Silva","userId":"17436513754207821399"},"user_tz":-60},"id":"vZO-I_yEzWjW","outputId":"79ea6498-23a1-403c-aa94-a582532c29a2"},"outputs":[{"data":{"text/html":["<div><div id=b239cde9-6891-4226-834e-44d08f90c066 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('b239cde9-6891-4226-834e-44d08f90c066').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>artist_count</th>\n","      <th>released_year</th>\n","      <th>released_month</th>\n","      <th>released_day</th>\n","      <th>in_spotify_playlists</th>\n","      <th>in_spotify_charts</th>\n","      <th>in_apple_playlists</th>\n","      <th>in_apple_charts</th>\n","      <th>in_deezer_charts</th>\n","      <th>bpm</th>\n","      <th>danceability_%</th>\n","      <th>valence_%</th>\n","      <th>energy_%</th>\n","      <th>acousticness_%</th>\n","      <th>instrumentalness_%</th>\n","      <th>liveness_%</th>\n","      <th>speechiness_%</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>953.000000</td>\n","      <td>953.000000</td>\n","      <td>953.000000</td>\n","      <td>953.000000</td>\n","      <td>953.000000</td>\n","      <td>953.000000</td>\n","      <td>953.000000</td>\n","      <td>953.000000</td>\n","      <td>953.000000</td>\n","      <td>953.000000</td>\n","      <td>953.00000</td>\n","      <td>953.000000</td>\n","      <td>953.000000</td>\n","      <td>953.000000</td>\n","      <td>953.000000</td>\n","      <td>953.000000</td>\n","      <td>953.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>1.556139</td>\n","      <td>2018.238195</td>\n","      <td>6.033578</td>\n","      <td>13.930745</td>\n","      <td>5200.124869</td>\n","      <td>12.009444</td>\n","      <td>67.812172</td>\n","      <td>51.908709</td>\n","      <td>2.666317</td>\n","      <td>122.540399</td>\n","      <td>66.96957</td>\n","      <td>51.431270</td>\n","      <td>64.279119</td>\n","      <td>27.057712</td>\n","      <td>1.581322</td>\n","      <td>18.213012</td>\n","      <td>10.131165</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.893044</td>\n","      <td>11.116218</td>\n","      <td>3.566435</td>\n","      <td>9.201949</td>\n","      <td>7897.608990</td>\n","      <td>19.575992</td>\n","      <td>86.441493</td>\n","      <td>50.630241</td>\n","      <td>6.035599</td>\n","      <td>28.057802</td>\n","      <td>14.63061</td>\n","      <td>23.480632</td>\n","      <td>16.550526</td>\n","      <td>25.996077</td>\n","      <td>8.409800</td>\n","      <td>13.711223</td>\n","      <td>9.912888</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>1930.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>31.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>65.000000</td>\n","      <td>23.00000</td>\n","      <td>4.000000</td>\n","      <td>9.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>3.000000</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1.000000</td>\n","      <td>2020.000000</td>\n","      <td>3.000000</td>\n","      <td>6.000000</td>\n","      <td>875.000000</td>\n","      <td>0.000000</td>\n","      <td>13.000000</td>\n","      <td>7.000000</td>\n","      <td>0.000000</td>\n","      <td>100.000000</td>\n","      <td>57.00000</td>\n","      <td>32.000000</td>\n","      <td>53.000000</td>\n","      <td>6.000000</td>\n","      <td>0.000000</td>\n","      <td>10.000000</td>\n","      <td>4.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>1.000000</td>\n","      <td>2022.000000</td>\n","      <td>6.000000</td>\n","      <td>13.000000</td>\n","      <td>2224.000000</td>\n","      <td>3.000000</td>\n","      <td>34.000000</td>\n","      <td>38.000000</td>\n","      <td>0.000000</td>\n","      <td>121.000000</td>\n","      <td>69.00000</td>\n","      <td>51.000000</td>\n","      <td>66.000000</td>\n","      <td>18.000000</td>\n","      <td>0.000000</td>\n","      <td>12.000000</td>\n","      <td>6.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>2.000000</td>\n","      <td>2022.000000</td>\n","      <td>9.000000</td>\n","      <td>22.000000</td>\n","      <td>5542.000000</td>\n","      <td>16.000000</td>\n","      <td>88.000000</td>\n","      <td>87.000000</td>\n","      <td>2.000000</td>\n","      <td>140.000000</td>\n","      <td>78.00000</td>\n","      <td>70.000000</td>\n","      <td>77.000000</td>\n","      <td>43.000000</td>\n","      <td>0.000000</td>\n","      <td>24.000000</td>\n","      <td>11.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>8.000000</td>\n","      <td>2023.000000</td>\n","      <td>12.000000</td>\n","      <td>31.000000</td>\n","      <td>52898.000000</td>\n","      <td>147.000000</td>\n","      <td>672.000000</td>\n","      <td>275.000000</td>\n","      <td>58.000000</td>\n","      <td>206.000000</td>\n","      <td>96.00000</td>\n","      <td>97.000000</td>\n","      <td>97.000000</td>\n","      <td>97.000000</td>\n","      <td>91.000000</td>\n","      <td>97.000000</td>\n","      <td>64.000000</td>\n","    </tr>\n","  </tbody>\n","</table></div>"],"text/plain":["       artist_count  released_year  released_month  released_day  \\\n","count    953.000000     953.000000      953.000000    953.000000   \n","mean       1.556139    2018.238195        6.033578     13.930745   \n","std        0.893044      11.116218        3.566435      9.201949   \n","min        1.000000    1930.000000        1.000000      1.000000   \n","25%        1.000000    2020.000000        3.000000      6.000000   \n","50%        1.000000    2022.000000        6.000000     13.000000   \n","75%        2.000000    2022.000000        9.000000     22.000000   \n","max        8.000000    2023.000000       12.000000     31.000000   \n","\n","       in_spotify_playlists  in_spotify_charts  in_apple_playlists  \\\n","count            953.000000         953.000000          953.000000   \n","mean            5200.124869          12.009444           67.812172   \n","std             7897.608990          19.575992           86.441493   \n","min               31.000000           0.000000            0.000000   \n","25%              875.000000           0.000000           13.000000   \n","50%             2224.000000           3.000000           34.000000   \n","75%             5542.000000          16.000000           88.000000   \n","max            52898.000000         147.000000          672.000000   \n","\n","       in_apple_charts  in_deezer_charts         bpm  danceability_%  \\\n","count       953.000000        953.000000  953.000000       953.00000   \n","mean         51.908709          2.666317  122.540399        66.96957   \n","std          50.630241          6.035599   28.057802        14.63061   \n","min           0.000000          0.000000   65.000000        23.00000   \n","25%           7.000000          0.000000  100.000000        57.00000   \n","50%          38.000000          0.000000  121.000000        69.00000   \n","75%          87.000000          2.000000  140.000000        78.00000   \n","max         275.000000         58.000000  206.000000        96.00000   \n","\n","        valence_%    energy_%  acousticness_%  instrumentalness_%  liveness_%  \\\n","count  953.000000  953.000000      953.000000          953.000000  953.000000   \n","mean    51.431270   64.279119       27.057712            1.581322   18.213012   \n","std     23.480632   16.550526       25.996077            8.409800   13.711223   \n","min      4.000000    9.000000        0.000000            0.000000    3.000000   \n","25%     32.000000   53.000000        6.000000            0.000000   10.000000   \n","50%     51.000000   66.000000       18.000000            0.000000   12.000000   \n","75%     70.000000   77.000000       43.000000            0.000000   24.000000   \n","max     97.000000   97.000000       97.000000           91.000000   97.000000   \n","\n","       speechiness_%  \n","count     953.000000  \n","mean       10.131165  \n","std         9.912888  \n","min         2.000000  \n","25%         4.000000  \n","50%         6.000000  \n","75%        11.000000  \n","max        64.000000  "]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# Descriptive statistics for numerical columns\n","desc_stats = df.describe()\n","desc_stats"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O-0DYs0mL-_Q"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"EK110WuJOxrm"},"source":["## 3. Data Preparation\n","\n","This stage often consumes the most amount of time in data science projects. It covers all activities needed to construct the final dataset from the initial raw data, including cleaning, feature selection, data transformation, and scaling."]},{"cell_type":"markdown","metadata":{"id":"IfDKlEzrO1tj"},"source":["## 4. Modeling\n","\n","Various modeling techniques are selected and applied, and their parameters are calibrated to optimal values, usually through iteration and cross-validation.\n"]},{"cell_type":"markdown","metadata":{"id":"INZlQhUiO3Sh"},"source":["## 5. Evaluation\n","\n","After one or more models are developed, they need to be evaluated with respect to the business objectives. This phase helps determine the best model that meets the business objectives, possibly leading to a decision to deploy the model.\n"]},{"cell_type":"markdown","metadata":{"id":"aTR5ctlrO435"},"source":["## 6. Deployment\n","\n","The knowledge gained will need to be organized and presented in a way that the customer can use it. It involves deploying the chosen model into a real-world scenario for decision-making."]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP4zRMBGGf08UJNWzV9EeGj","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
